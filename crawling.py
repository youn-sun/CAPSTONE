import time
import os
import requests
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from PIL import Image
from io import BytesIO

# ì›¹ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# í¬ë¡¤ë§í•  URL ì„¤ì •
url = "https://www.airbnb.co.kr/s/%EC%84%9C%EC%9A%B8/homes?refinement_paths%5B%5D=%2Fhomes"

# Airbnb ì‚¬ì´íŠ¸ ì—´ê¸°
driver.get(url)

# í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, "//*[contains(@class, 'c4mnd7m')]")))

print("âœ… Airbnb í˜ì´ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì—´ë ¸ìŠµë‹ˆë‹¤.")

# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±
img_folder = "airbnb_images"
os.makedirs(img_folder, exist_ok=True)

# ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
data_list = []
img_index = 1  

# í•¨ìˆ˜: ìˆ™ì†Œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¶€ë¶„
def get_data_from_page():
    global data_list, img_index
    for i in range(1, 19):  # ìƒìœ„ 18ê°œ ìˆ™ì†Œ í™•ì¸
        try:
            xpath = f"(//div[contains(@class, 'c4mnd7m')])[{i}]//a"
            link_element = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath)))
            link = link_element.get_attribute("href")
            print(f"ğŸ”¹ {img_index}. ìˆ™ì†Œ ë§í¬: {link}")
            
            # ì´ë¯¸ì§€ URLì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
            def fetch_image_url():
                driver.execute_script(f"window.open('{link}', '_blank');")
                time.sleep(2)
                all_windows = driver.window_handles
                driver.switch_to.window(all_windows[-1])  
                
                try:
                    img_element = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.XPATH, "//picture//img"))
                    )
                    img_url = img_element.get_attribute("src")
                    return img_url
                except:
                    return None
            
            # ì´ë¯¸ì§€ URL ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
            img_url = fetch_image_url()
            
            if img_url:
                print(f"   ğŸ–¼ï¸ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ URL: {img_url}")
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
                response = requests.get(img_url)
                if response.status_code == 200:
                    img = Image.open(BytesIO(response.content))
                    img_path = os.path.join(img_folder, f"ìˆ™ì†Œ_{img_index}.jpg")
                    img.save(img_path)
                    print(f"   âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {img_path}")
                else:
                    print(f"   âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

            rating = None
            try:
                rating = WebDriverWait(driver, 3).until(
                    EC.presence_of_element_located((By.XPATH, "//div[@class='r1lutz1s atm_c8_o7aogt atm_c8_l52nlx__oggzyc dir dir-ltr']"))
                ).text.strip()
                rating = ''.join([c for c in rating if c.isdigit() or c == '.'])
                rating = float(rating) if rating else None
            except Exception as e:
                print(f"   âŒ í‰ì  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ë°ì´í„° ì €ì¥
            data_list.append({
                "ìˆ™ì†Œ ë§í¬": link,
                "í‰ì ": rating,
                "ì´ë¯¸ì§€ íŒŒì¼": img_path if img_url else "N/A"
            })

            driver.close()  # ìƒˆ íƒ­ ë‹«ê¸°
            driver.switch_to.window(driver.window_handles[0])  # ì›ë˜ íƒ­ìœ¼ë¡œ ëŒì•„ê°€ê¸°

            img_index += 1  

        except Exception as e:
            print(f"âŒ {i}. ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

# í¬ë¡¤ë§ì„ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜
def crawl_pages(start_page, end_page):
    global data_list, img_index
    for page in range(start_page, end_page + 1):
        print(f"\nğŸ”¹ {page} í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘!")
        if page > 1:
            next_page_button = driver.find_element(By.XPATH, f'//*[@id="site-content"]/div/div[3]/div/div/div/nav/div/a[{page}]')
            next_page_button.click()
            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, "//*[contains(@class, 'c4mnd7m')]")))
        
        get_data_from_page()

    # ë°ì´í„° ì €ì¥ (CSV íŒŒì¼)
    df = pd.DataFrame(data_list)
    csv_path = "airbnb_data.csv"
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {csv_path}")

# í¬ë¡¤ë§ ì‹œì‘
if __name__ == "__main__":
    start_page = 1
    end_page = 30  # ì›í•˜ëŠ” í˜ì´ì§€ ë²”ìœ„ë¡œ ì„¤ì •
    crawl_pages(start_page, end_page)
    driver.quit()
